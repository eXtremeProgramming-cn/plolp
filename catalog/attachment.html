
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Attachment Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="relevance.html" />
    
    
    <link rel="prev" href="online_search.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Opening</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Organizing Prompts</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="long_prompt.html">
            
                <a href="long_prompt.html">
            
                    
                    Long Prompt
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="prompt_file.html">
            
                <a href="prompt_file.html">
            
                    
                    Prompt File
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="chapter.html">
            
                <a href="chapter.html">
            
                    
                    Chapter
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Defining Tasks</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="problem_orientation.html">
            
                <a href="problem_orientation.html">
            
                    
                    Problem Orientation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="prescribed_process.html">
            
                <a href="prescribed_process.html">
            
                    
                    Prescribed Process
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="example.html">
            
                <a href="example.html">
            
                    
                    Example
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Setting Context</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="persona.html">
            
                <a href="persona.html">
            
                    
                    Persona Adoption
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="audience.html">
            
                <a href="audience.html">
            
                    
                    Audience
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="epistemology_frame.html">
            
                <a href="epistemology_frame.html">
            
                    
                    Epistemology Frame
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Structuring Input</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="exhaustive_input.html">
            
                <a href="exhaustive_input.html">
            
                    
                    Exhaustive Input
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="online_search.html">
            
                <a href="online_search.html">
            
                    
                    Online Search
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="5.3" data-path="attachment.html">
            
                <a href="attachment.html">
            
                    
                    Attachment
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="relevance.html">
            
                <a href="relevance.html">
            
                    
                    Relevance
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Shaping Output</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="structured_output.html">
            
                <a href="structured_output.html">
            
                    
                    Structured Output
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="style_mimicry.html">
            
                <a href="style_mimicry.html">
            
                    
                    Style Mimicry
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="formatting_constraints.html">
            
                <a href="formatting_constraints.html">
            
                    
                    Formatting Constraints
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="deconstruction.html">
            
                <a href="deconstruction.html">
            
                    
                    Deconstruction
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Sharpening Your Mind</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="trial_and_error.html">
            
                <a href="trial_and_error.html">
            
                    
                    Trial and Error
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="iteration.html">
            
                <a href="iteration.html">
            
                    
                    Iteration
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="decomposition.html">
            
                <a href="decomposition.html">
            
                    
                    Decomposition
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="precision.html">
            
                <a href="precision.html">
            
                    
                    Precision
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="brainstorm.html">
            
                <a href="brainstorm.html">
            
                    
                    Brainstorm
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="criticism.html">
            
                <a href="criticism.html">
            
                    
                    Criticism
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Attachment</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="attachment">Attachment</h1>
<p><em>Attach reference files to your prompt for context and future reuse.</em></p>
<h2 id="motivation">Motivation</h2>
<p>When a task involves heavy reference material (like a long article, legal document, or dataset), providing that content in the prompt itself can be impractical or impossible due to length. If you omit these materials, the LLM lacks critical context and may produce incorrect or generic answers. Conversely, summarizing large documents in the prompt is time-consuming and risks leaving out important details.</p>
<h2 id="solution">Solution</h2>
<p>Attach relevant documents or files to your prompt instead of trying to paste their entire content. For example, you can attach a research paper, a policy document, or a set of data, then instruct the LLM to use that attachment when formulating its answer. This way, the LLM has access to the detailed information it needs without cluttering your prompt text. Using attachments not only gives the model the exact references required, but also makes your prompting process more modular. You can reuse those files for other prompts and build a personal library of reference materials for future use.</p>
<h2 id="challenge">Challenge</h2>
<p>It&#x2019;s a common frustration: you have a complex task for an AI assistant that depends on a lot of background information, but getting all that information into your prompt is a struggle. Large Language Models can only handle a limited amount of text in one go (their <em>context window</em>), so extremely long inputs often get cut off or refused. This limitation leads users to attempt various workarounds, each with its own challenges:</p>
<ul>
<li><p><strong>Skipping the references altogether:</strong> Some users simply ask the LLM a question without providing the source material, hoping the model&#x2019;s general knowledge will suffice. Often, this yields shallow or incorrect responses because the model lacks the specific context. <em>For instance, a high school teacher asked an AI to generate quiz questions about a short story her class read. Since she didn&#x2019;t provide the story text (assuming the AI might know it), the questions came out generic and didn&#x2019;t align with the story&#x2019;s details.</em> The omission of the actual text left the model guessing, which frustrated the teacher when she saw the irrelevant results.</p>
</li>
<li><p><strong>Copy-pasting the full text into the prompt:</strong> Another approach is to dump a huge chunk of text directly into the prompt. However, most AI platforms impose limits on input size. If a school administrator tries to paste a 50-page education policy document into a chat box, the interface might simply refuse to accept it or truncate the latter half without warning. Even when an interface <em>does</em> allow a very large paste, navigating such a bloated prompt becomes unwieldy for both the user and the model. The important instructions or questions can get lost in a sea of text. In our example, if the teacher had tried to paste the entire short story (several thousand words) before asking for quiz questions, she&#x2019;d likely hit a limit or overwhelm the model, defeating the purpose of a quick solution.</p>
</li>
<li><p><strong>Manually summarizing or excerpting the source:</strong> In an attempt to avoid overloading the prompt, users might summarize the reference materials themselves or copy only select excerpts. This is labor-intensive and error-prone. A knowledge worker in a government office might spend hours condensing a detailed policy report down to a few key paragraphs to fit into a prompt. Unfortunately, in doing so they might omit subtle points or data that turn out to be important. When the LLM generates an analysis from this summarized input, it could miss crucial nuances simply because those details never made it into the prompt. The user is left wondering if the AI is flawed, when in fact the AI was starved of half the facts.</p>
</li>
<li><p><strong>Feeding information piecemeal in a multi-turn exchange:</strong> Sometimes people try to break a large document into smaller sections and feed these to the LLM one by one over several messages. For example, an analyst might send an AI the first 5 pages of a lengthy report, then the next 5 pages, and so on, and finally ask a question about the whole report. While this can bypass single-message size limits, it quickly becomes cumbersome. The user has to manage the conversation carefully, and there&#x2019;s a risk the model forgets or confuses earlier details by the time it processes later ones. Continuously reminding the AI about previous parts or stitching together partial answers is difficult. Our teacher could have attempted to split the short story into chunks and present them in sequence, but keeping track of what the AI retained from the beginning of the story by the end would be challenging. The flow of context can break unless the user is extremely careful at each step.</p>
</li>
<li><p><strong>Relying on the AI&#x2019;s built-in knowledge:</strong> There&#x2019;s also the temptation to assume the LLM might have seen a similar document in its training data and can fill in details on its own. This often leads to <strong>hallucinations</strong> &#x2013; the AI will confidently fabricate information or incorrectly recall facts. Imagine an office administrator asking for an analysis of a proprietary internal report without providing it, thinking the AI might have general knowledge of the topic. The AI might produce an analysis filled with generic statements or made-up data that sounds plausible but is entirely detached from the actual report. The administrator ends up with output that can&#x2019;t be trusted, having to double-check everything against the real document &#x2013; negating any time saved.</p>
</li>
</ul>
<p>In each of these scenarios, the core challenge is the same: the user needs the LLM to have <em>access</em> to a large amount of reference information, but straightforwardly giving that information to the model is difficult. Either it won&#x2019;t fit, or it&#x2019;s too time-consuming to prepare, or the model is left unguided. The result is often frustration&#x2014;important details get lost, the model&#x2019;s answers miss the mark, and the user has to do extra work to correct or refine the output.</p>
<p>This problem is especially pronounced for professionals like educators, administrators, and researchers. They often deal with lengthy documents: a teacher might have a detailed curriculum guide, an administrator might have a stack of policy regulations, and a researcher might have dozens of pages of study data. These users aren&#x2019;t programmers or AI experts who enjoy wrestling with prompt limitations; they just want the AI to help with the content at hand. When the usual prompting methods fail, it feels like hitting a wall: <em>&#x201C;I have all the info right here, but the AI can&#x2019;t seem to use it!&#x201D;</em></p>
<p>Ultimately, the challenge comes down to providing <strong>complete context</strong>. You want the richness of the source material to inform the AI&#x2019;s output, but you also need a convenient way to get that material into the AI&#x2019;s input. Without a better method, you&#x2019;re stuck either oversimplifying your request or spending too much effort tailoring the prompt. This is the pain point that leads many to discover the <strong>Attachment</strong> pattern as a solution.</p>
<h2 id="example">Example</h2>
<p>Attaching reference files to your prompt is a practical way to overcome these obstacles. By packaging the needed context separately from the main instructions, you ensure the AI has everything it needs without making the prompt itself unwieldy. Let&#x2019;s explore how this pattern can be applied in real situations, and how you can use it effectively.</p>
<h3 id="attaching-an-ideological-guide-and-samples-for-a-policy-memo">Attaching an Ideological Guide and Samples for a Policy Memo</h3>
<p>Consider a political analyst who regularly writes confidential internal reports (&#x5185;&#x53C2;) for government leaders. These reports must adhere to a specific ideology and format. In one case, the analyst needs to write about a current international issue from a Marxist perspective and in a style suitable for high-level officials. He has two crucial reference resources: a document on Marxist epistemology (which outlines the philosophical lens for analysis) and a couple of exemplary internal reports from previous years that illustrate the expected structure and tone.</p>
<p>Using the Attachment pattern, the analyst prepares his prompt in a structured way. In his prompt file, he creates a section titled <strong>&#x201C;Attachments&#x201D;</strong> where he lists each reference file with a label and a brief description:</p>
<ul>
<li><p><strong>Attachment 1: Marxist_Epistemology.docx</strong> &#x2013; <em>A primer on Marxist theory and perspective. Use this as the ideological foundation for the analysis (guiding principles, not to be quoted directly).</em></p>
</li>
<li><p><strong>Attachment 2: Internal_Report_Example1.pdf</strong> &#x2013; <em>An example of a well-written internal reference report from last year. Note the formal tone, structure, and phrasing used.</em></p>
</li>
<li><p><strong>Attachment 3: Internal_Report_Example2.pdf</strong> &#x2013; <em>Another sample internal report (unrelated content). Pay attention to how the arguments are presented concisely and the style of recommendations.</em></p>
</li>
</ul>
<p>By explicitly listing these, the analyst makes it clear to the LLM what each attached document is and how it should inform the task. In the main prompt instructions (outside the attachment list), he then writes something like: <em>&#x201C;Please read the current issue briefing (provided separately) and write an internal reference report in Chinese. Use Attachment 1 to inform your ideological stance and analytical approach, and follow the writing style and structure seen in Attachments 2 and 3. Do <strong>not</strong> mention the attachments explicitly in the report, but let their content guide your writing.&#x201D;</em></p>
<p>When the LLM processes this prompt, it will load the full content of those attached files (the theory document and the example reports) along with the user&#x2019;s instructions. The model doesn&#x2019;t need the analyst to paste pages of theory or examples into the prompt &#x2014; it already has them in Attachment 1, 2, and 3. As a result, the AI generates a report that is richly informed: the arguments implicitly reflect Marxist analysis (thanks to Attachment 1), and the writing style closely mimics the terse, authoritative tone of the provided examples (attachments 2 and 3). The analyst receives a draft that aligns with the required ideology and format almost perfectly, requiring only minimal tweaks.</p>
<p>This example shows the power of attachments for complex, reference-heavy tasks. The user was able to guide the LLM with extensive background material without cluttering the prompt. Equally important, those attachments are <em>reusable</em>. The Marxist theory document (Attachment 1) is a resource the analyst can attach to any future prompt that needs a similar ideological angle, saving time in the long run. The example reports (Attachment 2 and 3) serve as templates for style &#x2013; whenever a new internal memo is needed, those can be attached again to ensure consistency in voice and structure. In essence, the analyst has built a mini library of references that can be plugged into new prompts as needed, embodying the &#x201C;modular&#x201D; benefit of this pattern.</p>
<h3 id="summarizing-a-news-article-with-the-article-as-attachment">Summarizing a News Article with the Article as Attachment</h3>
<p>Now let&#x2019;s look at a more everyday scenario: a news editor needs to create a summary of a lengthy news article for a daily digest. She has a well-crafted prompt template that specifies how to structure a summary (mention the headline, key points, context, and so on) to maintain consistency across summaries. The challenge is that every day, the article to be summarized is different and often several thousand words long. Manually copying each article&#x2019;s text into the prompt would be tedious and often not even possible due to size limits.</p>
<p>Instead, the editor uses the Attachment pattern. Whenever she needs to summarize a new article, she simply attaches the article&#x2019;s text file to the prompt. In the prompt file, under an &#x201C;Attachments&#x201D; section, it might say:</p>
<ul>
<li><strong>Attachment 1: Source_Article.txt</strong> &#x2013; <em>The full text of the news story to summarize. This is the content you will condense into the digest format.</em></li>
</ul>
<p>The rest of her prompt (the instructions to the LLM) can remain the same each time. For example, she might write: <em>&#x201C;You are a news assistant. Please read Attachment 1 and produce a concise summary in three paragraphs: the first paragraph should state the main point of the article, the second should provide key supporting details or facts, and the third should give any necessary background or context. Preserve any important names or figures from the article, but omit minor details.&#x201D;</em> Notice that she doesn&#x2019;t need to paste the article text anywhere in these instructions; referring to &#x201C;Attachment 1&#x201D; is enough, since the LLM has that file.</p>
<p>By doing this, the editor achieves multiple things. First, <strong>accuracy</strong>: The LLM&#x2019;s summary is based on the actual article text, so it&#x2019;s far less likely to introduce errors or miss critical information. All the specifics (names, dates, quotes) are available to the model in the attachment, and thus can be reflected correctly in the summary. Second, <strong>efficiency</strong>: She can reuse her summary-writing prompt every day, simply swapping out the attachment for whichever article is on deck. The template doesn&#x2019;t need to be rewritten or adjusted for length, because the article content lives in its own file. Third, <strong>manageability</strong>: the prompt she works with is short and clear &#x2013; she sees just her instructions and a reference to &#x201C;Attachment 1,&#x201D; rather than wading through pages of article text to find where to add her directives.</p>
<p>This approach isn&#x2019;t limited to news articles. Any time you want an LLM to process a specific piece of content &#x2013; whether it&#x2019;s a long report, a transcript of a meeting, a chapter from a textbook, or a piece of fiction &#x2013; you can attach that content as a separate file. For example, an educator could attach a PDF of a historical speech and ask the LLM to generate comprehension questions about it. A business analyst could attach an exported data table and prompt the LLM to analyze trends from it. The key is that the bulk of the content stays in a file, while the prompt focuses on the task. Attaching the source material means the AI has the full thing to refer to, enabling detailed and context-aware outputs like summaries, analyses, or Q&amp;As, all tailored to the actual content at hand.</p>
<h3 id="providing-a-writing-sample-to-imitate-style-and-tone">Providing a Writing Sample to Imitate Style and Tone</h3>
<p>Attachments are not just useful for factual or data-heavy references&#x2014;they can also be used to convey a <em>style</em> or <em>tone</em>. Suppose you want the AI to write in the voice of a particular author or to match the style of a specific publication. One effective way to do this is by attaching a sample of the desired style for the AI to learn from.</p>
<p>For instance, the authors of <em>Pattern Language of LLM Prompting</em> (the very book you&#x2019;re reading) wanted a consistent, clear style inspired by Martin Fowler&#x2019;s famous book <em>Refactoring</em>. Fowler&#x2019;s writing is known for its clarity, structure, and approachability, and the authors aimed to channel that in this book. To achieve this, they applied the Attachment pattern: they provided the LLM with an attachment containing an excerpt from <em>Refactoring</em> itself as a style reference.</p>
<p>In the prompt file for writing a chapter, they included an attachment entry such as:</p>
<ul>
<li><strong>Attachment 1: Fowler_Refactoring_Excerpt.pdf</strong> &#x2013; <em>An excerpt from &#x201C;Refactoring&#x201D; by Martin Fowler, illustrating the desired writing style (structured explanations, concise language).</em></li>
</ul>
<p>The instructions in the prompt then guided the model with a line like: <em>&#x201C;Use the writing style in Attachment 1 as a guide when composing the chapter. The tone should be pragmatic, instructional, and easy to follow, similar to Martin Fowler&#x2019;s style.&#x201D;</em></p>
<p>By giving the model this sample, the authors enabled the LLM to pick up on the nuances of Fowler&#x2019;s prose &#x2014; for example, how he organizes content into headings and short paragraphs, how he uses simple language to explain complex ideas, and the generally matter-of-fact tone he employs. The AI, having read the attached excerpt, could then mirror those qualities in the new chapter it was writing. The result was a draft that felt notably closer to Fowler&#x2019;s style than one would get by simply saying &#x201C;write in a clear and structured manner.&#x201D; The attachment provided a concrete example of the target style, which is far more instructive to the model than a vague description.</p>
<p>This pattern can be used by anyone looking to emulate a style. A novelist might attach a few pages of Hemingway if they want a Hemingway-like narration for a scene. A marketing team could attach a past press release as a style template for the AI to follow when drafting a new announcement. In all these cases, the attachment serves as a <strong>reference point</strong> for tone, voice, and formatting. The LLM uses it as a model to shape its output, ensuring consistency with the desired style.</p>
<h3 id="how-to-apply-the-attachment-pattern">How to Apply the Attachment Pattern</h3>
<p>As the examples above show, attaching reference files can dramatically improve the quality and relevance of an LLM&#x2019;s output for complex tasks. To apply this pattern in your own prompting, consider the following general steps:</p>
<ol>
<li><p><strong>Identify the reference materials you need:</strong> Determine what background content would help the AI produce a better result. This could be a source text (like an article to summarize), supporting documents (research, manuals, guidelines), or examples of the desired output (sample reports or writings). Gather those into accessible files. </p>
</li>
<li><p><strong>Add them as attachments in your prompt environment:</strong> Use your AI platform&#x2019;s feature to attach or upload files alongside your prompt. Many advanced LLM interfaces allow you to provide files or have an &#x201C;Attachments&#x201D; section in a prompt file. If your interface doesn&#x2019;t explicitly support file attachments, you can simulate this by clearly separating the reference text from your main instructions (for example, by pasting it at the end of the prompt or in a preceding message) &#x2013; but be mindful of length limits. The ideal scenario is an interface where you can simply upload the file or point the model to it.</p>
</li>
<li><p><strong>Label and describe each attachment:</strong> In the prompt text that you do write, include a brief section listing the attachments by name or number with a one-line description of each. This is crucial for clarity. It tells the model <em>what</em> it&#x2019;s looking at and <em>how it should use it</em>. For example:  </p>
<ul>
<li><em>Attachment 1: &#x201C;2024_Quarterly_Report.pdf&#x201D; &#x2013; Detailed financial data and analysis for Q1 and Q2 of 2024.</em>  </li>
<li><em>Attachment 2: &#x201C;Company_Style_Guide.docx&#x201D; &#x2013; Writing guidelines and tone to use for all internal memos.</em><br>These descriptions act as instructions tied to the attachments, so the model knows the role of each file.</li>
</ul>
</li>
<li><p><strong>Reference attachments in your instructions:</strong> When you write the prompt&#x2019;s main instruction or question, make it a point to mention the attachments as needed. For instance: <em>&#x201C;Using the data in Attachment 1, draft a summary of our Q2 performance. Follow the format and tone given in Attachment 2.&#x201D;</em> By explicitly naming the attachments in your request, you ensure the model consults those files when generating its answer. It&#x2019;s like telling a human, &#x201C;use those documents I gave you when you write this.&#x201D;</p>
</li>
<li><p><strong>Reuse and maintain your reference files:</strong> Once you have attachments set up for a task, you can keep them for future use. If you frequently summarize news articles, having a template prompt with an attachment slot is handy &#x2013; you just plug in a new article each time. If you always need a certain style or knowledge base, keep those files ready to attach. Over time, you&#x2019;ll build up a collection of useful attachments (previous reports, style guides, foundational texts, etc.). This library of reference files becomes a valuable asset. It means that for a new prompt, you might not need to hunt down information or copy-paste anything at all &#x2013; you already have the relevant documents on hand to attach as context.</p>
</li>
</ol>
<p>By following these steps, you take full advantage of the <strong>Attachment</strong> pattern. In short, this pattern lets you give the AI <em>the right information at the right time</em>. Instead of being constrained by prompt size or forced to strip down context, you hand over the complete resources and let the model do what it&#x2019;s good at: synthesizing and responding based on all available information. The result is more accurate, context-rich outputs with far less hassle. Your prompts become cleaner and more focused, and your interactions with the LLM become more powerful because you&#x2019;re always able to provide the supporting knowledge it needs.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="online_search.html" class="navigation navigation-prev " aria-label="Previous page: Online Search">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="relevance.html" class="navigation navigation-next " aria-label="Next page: Relevance">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Attachment","level":"5.3","depth":1,"next":{"title":"Relevance","level":"5.4","depth":1,"path":"catalog/relevance.md","ref":"catalog/relevance.md","articles":[]},"previous":{"title":"Online Search","level":"5.2","depth":1,"path":"catalog/online_search.md","ref":"catalog/online_search.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css","website":"styles/website.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css","website":"styles/website.css"}},"file":{"path":"catalog/attachment.md","mtime":"2025-04-18T15:23:10.149Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2025-04-18T15:23:41.646Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

