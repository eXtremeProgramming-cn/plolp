# Epistemology Frame

*Provide a guiding ideology or worldview to shape the LLM's thinking.*

## Motivation

Without a guiding philosophy or perspective, an LLM will usually default to a neutral (often implicitly Western-centric) standpoint that might not align with the intended angle of analysis. Tasks that require a specific ideological or methodological viewpoint may suffer because the model isn’t inherently biased toward that approach. This can result in output that lacks the depth, nuance, or flavor of the desired perspective. In contexts where a certain worldview is expected—such as educational content aligned with a national ideology or an analysis from a Marxist lens—this neutrality (or hidden bias) can be a significant drawback for the user.

## Solution

Explicitly state in your prompt the philosophical, ideological, or methodological framework that the LLM should adopt for the task at hand. For example, you can instruct the model to approach the problem from a Marxist perspective, a libertarian viewpoint, a religious outlook, or to apply a particular methodology (like the scientific method). By providing such a frame, you implicitly shape how the LLM reasons through the task, aligning its thought process and tone with that viewpoint. This technique can deeply influence the nature of the answer, ensuring the output stays consistent with the chosen perspective and contains the desired analytical flavor.

## Challenge

When an LLM user skips providing an ideological or methodological frame, they often encounter frustrating results. **The most common issue is generic or lukewarm outputs.** By default, LLMs tend to give balanced, neutral answers. While neutrality sounds good in theory, in practice it can mean the response doesn’t truly satisfy *any* perspective in depth. Imagine asking for an analysis of a contentious policy, expecting a critical angle, and getting back a bland summary that sits on the fence. The answer might be technically correct yet completely miss the intended *stance* or insight. This generic quality can make the output feel shallow or obvious, especially to a domain expert or an audience looking for a specific angle.

Another challenge is that **LLMs carry implicit biases from their training data.** Most mainstream LLMs have been trained on large swaths of internet and literature, much of it reflecting Western liberal-democratic norms or other dominant paradigms. If you ask a question without setting a frame, the model’s “neutral” answer may actually lean toward those ingrained biases. For example, a *neutral* answer about economic policy might implicitly favor free-market assumptions, simply because that perspective is common in the training material. A civil servant in a different political context—say, someone working under a socialist government or a community leader with a communalist philosophy—could find such answers subtly misaligned or even inappropriate. The user might sense that the response has a certain ideological tilt (too individualistic, or too Eurocentric, for instance) even though they didn’t ask for it. In politically or culturally sensitive projects, this misalignment isn’t just unsatisfying, it can lead to real problems: advice that contradicts policy, content that offends stakeholders, or analyses that miss critical local perspectives.

Consider a concrete scenario: **A public school administrator is reviewing history curriculum content using an LLM.** The school follows a national curriculum with a distinct perspective on history (perhaps emphasizing anti-colonial struggle and socialist principles). The administrator asks the LLM, “Evaluate this chapter on industrialization for any bias or missing perspectives.” Without guidance, the LLM might respond with a generic assessment: it may note that the chapter seems fact-based and perhaps mention in passing that “some perspectives, like cultural impacts or multiple national viewpoints, could be added.” This response is *not wrong*, but it’s far from what the administrator needs. It doesn’t mention class struggle, economic systems, or colonial contexts—because the LLM was never told to consider those specifically. The administrator was hoping for an analysis of whether the chapter adequately presents, say, the exploitation of workers or the role of imperialism. Instead, they got a surface-level critique. The core issue is that the LLM had no *point of view* to anchor its evaluation; it defaulted to broad-strokes neutrality.

Such outcomes highlight a **practical gap**: the user expected the LLM to “just know” the angle to take, but the LLM isn’t clairvoyant. It doesn’t know the user’s underlying ideological expectations unless told. Non-technical users often assume the AI will automatically adjust to the context or the organization’s viewpoint. When it doesn’t, the result can be confusion (“Why did it respond like that?”) or disappointment (“This isn’t insightful at all”). In sensitive settings, it can even be risky. Imagine a scenario where a ministry official uses an LLM to draft a speech intended to reflect the government’s ideology. If the official simply provides factual points and asks for a polished speech, the LLM might produce something polished *but embedded with values or assumptions that conflict with the official line*. The official then has to comb through and adjust wording that might unintentionally quote liberal democratic ideals or individualistic framing, whereas their audience expects collectivist, communitarian rhetoric. The **lack of an explicit epistemology frame means extra work and potential embarrassment** if such biases slip through.

On the conceptual side, **an LLM without a frame lacks a compass for navigating contentious topics**. When faced with politically charged or value-laden questions, a model is often programmed (via alignment and training) to avoid taking extreme positions or sounding one-sided. It may hedge, give pros and cons of every side, or stick to factual reportage. This cautious balancing act is by design—AI developers often aim to make the default behavior inoffensive and broadly acceptable. But in doing so, the model’s answer can be unsatisfyingly equivocal. For a user who actually *wants* a strong stance or a deep dive from a particular angle, the model’s built-in neutrality feels like resistance. Users might try to press the model: “No, really, be critical from **this** viewpoint,” only to get a slightly more pointed answer that still feels superficial. The underlying challenge is that without a guiding framework, the model doesn’t have the language or focus to fully inhabit that viewpoint. It’s like asking someone to argue a case in court without telling them which side they’re on; they’ll default to a summary of both sides instead of a convincing argument for one.

**Hidden complexity**: Even if the user is aware of the need for a perspective and requests it (“Analyze this issue from a Marxist perspective” or “Give me a conservative take on this topic”), the results can be hit-or-miss unless the model is given substance to work with. A one-line instruction might make the LLM tilt its answer slightly (“From a Marxist perspective, one might say...”), but often it will be *Marxism-Lite*—a few references to class or capitalism thrown in without deeper analysis. The model isn’t trying to be shallow; it simply has a very general idea of what “Marxist perspective” means unless provided more detail. For nuanced or less common worldviews, the risk of misunderstanding is higher. If you ask for a specific religious or philosophical stance that the model isn’t strongly trained on, it might produce either a generic platitude or even a mistaken interpretation of that stance. This is frustrating for users who *do* have a particular, well-developed framework in mind: they see the AI fumbling to emulate an ideology, almost like an outsider who only half-understands it.

All these problems boil down to a core challenge: **without an explicit epistemology frame, the LLM’s internal “thinking” lacks direction**. The model has no shortage of information, but information alone doesn’t decide *which lens to apply*. Human experts know that how you interpret information depends on your theoretical framework. An economist with a Keynesian outlook will interpret data differently than one with a Hayekian free-market outlook; a historian rooted in postcolonial theory will read an event differently than one with a nationalist framework. An LLM, by contrast, has no permanent allegiance to any of these frameworks. It oscillates in whatever direction the prompt or context nudges it. If the prompt is silent on perspective, the model unconsciously falls back on the patterns most prevalent in its training. The result is like a ship drifting with currents because no one set the course.

For users in domains where perspective is everything, this is a serious hurdle. It’s not just academic. **In real workplace situations, the lack of a clear frame can waste time and even erode trust in the AI tool.** A policy analyst might run multiple queries trying to get the AI to “be more critical” or “take a different angle,” not realizing that the key missing piece is an upfront establishment of viewpoint. They might conclude the AI isn’t capable of the depth they need, when in fact, with the right prompt framing, it could deliver a very sophisticated analysis. The pattern of Epistemology Frame emerges from this very frustration: once users discover they can set the worldview of the AI, a lightbulb goes off. But discovering it is part of the challenge – it’s not an obvious solution to those new to prompting.

**Another challenge** lies in constructing the frame itself. Let’s say our user realizes they need to provide an ideological lens. How do they do that effectively? It’s not enough to say “Use Marxism” or “Think like a feminist scholar” and call it a day. Crafting a useful epistemology frame might require domain knowledge. Many users are not philosophers or theorists, so articulating *what exactly* Marxist analysis entails or *which principles* a feminist perspective should emphasize can be daunting. There’s a risk of oversimplification (“Marxism means talk about rich vs. poor”) which might lead to a caricatured output, or the opposite risk of being so vague that the model still doesn’t have clear guidance. In fact, experts who use this technique often prepare detailed guidelines or even attach reference material. For instance, an analyst might attach a multi-page internal document summarizing key Marxist concepts for analyzing society (covering historical materialism, class conflict, ideology, etc.) for the LLM to follow. Not everyone has such a document handy or the expertise to write one. This means that **the effort required to set up an epistemology frame can be a barrier** in itself. It’s a bit ironic: to get the AI to produce expert-style analysis, the user might first have to feed expert knowledge into the prompt.

Finally, users must be aware of the **trade-offs**. A strongly set epistemology frame will indeed bias the output toward that viewpoint (that’s the goal), but it can sometimes *overcorrect*. If you immerse the model in a very strict ideological narrative, it might start echoing jargon and talking points excessively. For example, if the frame is too zealous, the LLM’s answer could read like a one-sided polemic, losing nuance or ignoring any data that doesn’t fit the ideology. In a sense, you can succeed too well: the LLM becomes a true ideologue of the frame you gave it! While this may be desired in some cases (like writing a partisan op-ed), in other cases the user wants analysis with a flavor of that perspective but still grounded in facts. Achieving the right balance might require iteration: using the Epistemology Frame pattern in combination with others like *Persona* (to adjust tone) or *Refinement* (to tweak how extreme the output is). Non-technical users might not anticipate this and could be taken aback: “I asked for a Marxist analysis, but now it’s just spouting Marxist slogans.” Thus, part of the challenge is learning to calibrate how much framing to give, and possibly instructing the model to not lose critical thinking. For instance, one might add to the prompt, “use a Marxist perspective, but remain analytical and refer to evidence.”

In summary, the absence of a clear epistemological frame leads to a host of issues: neutral-but-unsatisfying answers, inadvertent bias misalignment, and a lack of depth in handling complex ideological questions. Users operating in environments with strong viewpoints (be it corporate culture, political ideology, or theoretical framework) quickly realize the AI’s default voice isn’t truly “neutral” in the way they need. The Epistemology Frame pattern is motivated by these very challenges: it gives the user a tool to set the AI’s compass. But applying that tool requires understanding the problem (why the AI acts like it does) and careful construction of the frame. Recognizing the need for a guiding worldview is the first step past the frustration of generic AI output. The next step is learning how to supply that guide effectively, which we explore in the example below.

## Example

Let’s walk through a concrete example to see the **Epistemology Frame** in action. We’ll use a scenario of analyzing media bias, a task where having a specific ideological lens dramatically changes the outcome. Imagine we have a user named Priya, who is a media analyst working for a public agency. Priya’s job is to ensure that news content is scrutinized for bias and that analyses align with her agency’s perspective. In this case, she wants to analyze a news article about a factory workers’ strike. The twist is that her agency expects a **Marxist-informed analysis** of media bias — in other words, an analysis that explicitly looks at class interests, power structures, and ideological framing in the news. Priya will use an LLM to help generate this analysis, but she needs the LLM to adhere to a Marxist worldview while doing so.

First, let’s consider what happens if Priya does **not** set an epistemology frame and just asks the question plainly. She provides the LLM with the text of the news article (or a summary of it) and then asks: *“Identify any biases in how this news article reports on the factory strike.”* 

For context, here’s a **summary of the news article** Priya is analyzing: The article is from a major newspaper. It describes a strike at a local factory. The piece quotes a government official and a factory executive who both emphasize the negative impact of the strike on the economy and public order. It briefly mentions that workers are demanding higher wages and better safety, but it doesn’t quote any workers directly. The article’s tone is that the strike is something disruptive that needs resolution for the sake of stability.

Without any ideological guidance, the LLM reads this input and produces a response. Given the default neutral stance, the **LLM’s output might look like this**:

**LLM Output (without epistemology frame):**

> The article appears to maintain a generally neutral tone but does exhibit subtle bias in its coverage of the factory strike. It primarily features perspectives from the government official and the factory executive, both of whom frame the strike negatively (as harmful to the economy and public order). This emphasis suggests a slight bias toward the management and official viewpoint. The workers’ perspective is only briefly mentioned and not elaborated with direct quotes, which indicates that their side of the story is underrepresented. By focusing on economic losses and stability, the article may implicitly favor the idea that ending the strike quickly is desirable, rather than exploring the workers’ grievances in depth. Including more insight from the workers or acknowledging the legitimacy of their demands would have made the coverage more balanced. Overall, the bias isn’t extremely overt, but the selection of sources and framing leans toward the anti-strike position.

This output is a fairly typical bias analysis from a neutral point of view. It’s not a *bad* answer. It correctly notes that the article mainly gives the management side and that the workers’ side is lacking. If Priya only wanted a basic analysis, this might suffice. However, recall that Priya’s aim (and her agency’s mandate) is to analyze bias from a **Marxist perspective**. The output above, while touching on imbalance, doesn’t use any Marxist concepts or deeper ideological critique. It doesn’t talk about class struggle, capitalism, or ideology; it’s basically describing an imbalance in sourcing. It’s the kind of analysis any savvy reader might do, not specifically a Marxist analysis.

Priya recognizes this. The output, though accurate in spots, doesn’t fulfill the brief she has: to critique the article *through the lens of class and power*. She realizes the LLM is just doing a general job. Now, Priya applies the **Epistemology Frame** pattern. She’s going to provide the LLM with a Marxist framework upfront, so that the next answer dives into the class analysis she needs.

To do this, Priya consults her agency’s internal guide titled *“Marxist Framework for Bias Analysis.”* It’s a document (in fact, a multi-layer framework) that breaks down how to analyze social issues and media from a Marxist worldview. The framework reminds the analyst to consider several layers: from broad philosophical stance down to specific biases. Priya doesn’t necessarily need to give the LLM the entire document word-for-word (that could be very long), but she decides to distill the key points into her prompt. Essentially, she will *teach* or prime the LLM with the Marxist lens before asking it to analyze the article again.

Here’s how Priya might incorporate the **epistemology frame** into the prompt (simplified for this example):

1. **Set the Worldview:** She instructs the LLM that for this task, it should adopt a historical materialist outlook. For example, she might write: *“Assume the perspective of a Marxist analyst. Focus on material conditions and class relations as the driving forces in society, rather than just individual choices or neutral facts.”* This aligns with the idea from the framework about **Materialist vs. Idealist** understanding (is what’s happening explained by material conditions or by ideals and individual intentions?). In a Marxist frame, material conditions (economics, class positions) are key.

2. **Highlight Class Relations:** Priya includes points about class dynamics. For instance: *“Consider the class positions of the people quoted or discussed. Identify which statements reflect the interests of the working class (proletariat) and which reflect the interests of owners or the ruling class (bourgeoisie).”* This directly guides the LLM to look at the article and categorize bias in terms of class interest – a very Marxist approach.

3. **Identify Ideological Framing:** She adds instructions based on the framework’s notion of how ideology appears in media. For example: *“Examine whether the article is framing the strike as a threat to social order or economy (which would indicate it’s taking the perspective of those in power). Note any language that portrays the workers as causing trouble versus language that would portray the owners as exploiters. Look for assumptions that the current system is ‘normal’ or ‘inevitable’ – this could be the article naturalizing the status quo.”* This relates to what the framework calls **“Naturalization of capitalist relations”** – media often assumes or implies that the capitalist way of organizing work (owners vs workers, profit motive, etc.) is normal and good, and anything that disrupts it (like a strike) is problematic.

4. **Use Marxist Terminology Appropriately:** She encourages the use of relevant terms if applicable: *“You can use concepts like class struggle, exploitation, capitalist, labor, etc., where relevant to describe the biases.”* This gives the LLM permission to speak in the language of Marxist critique, which it might avoid normally to keep a neutral tone.

5. **Maintain Analytical Tone:** Lastly, Priya might add a note to keep the analysis factual and reasoned: *“Provide the analysis in an explanatory tone, using Marxist theory to support points, but base it on evidence from the article.”* She doesn’t want the output to turn into a propaganda rant; it should still read like a logical analysis report, just one informed by Marxist theory.

By including these elements, Priya’s prompt has now set a robust epistemology frame. Effectively, she has told the LLM: *“This is the worldview and approach you should use to analyze the article.”* Now she poses the question again: *“Given the above perspective, analyze the biases in how the news article reports on the factory strike.”*

What difference do we expect? With this detailed framing, the LLM’s new response should delve into aspects it previously glossed over. It should talk about the power dynamics and the ideological bent of the coverage, not just source imbalance. Let’s look at a possible **LLM output with the Marxist epistemology frame applied**:

**LLM Output (with Marxist frame):**

> From a Marxist perspective, the news article exhibits a clear bias that aligns with the interests of the bourgeoisie (the factory management and government) over the proletariat (the workers). The article’s framing portrays the strike primarily as a threat to economic stability and public order, which reflects the viewpoint of the ruling class. This is evident in how the government official’s and factory executive’s statements dominate the narrative, emphasizing **economic losses** and the need to “maintain order.” Such language implicitly suggests that the **profits and continuity of business (capital)** are more important than the workers’ grievances. This *naturalizes* the idea that disrupting production (even for the workers’ welfare) is harmful, thereby **justifying the existing power relations**. 

> The workers, on the other hand, are barely given a voice. Their demands (higher wages and better safety) are mentioned only in passing, with no context or support, which diminishes the legitimacy of their perspective. In Marxist terms, this is a classic case of the media reinforcing **ideological hegemony**: the article legitimizes the capitalist standpoint (owners need to keep production going for the economy’s sake) while minimizing the labor standpoint (workers protesting exploitation). The absence of any worker quotes or detailed arguments is not an accident of reporting; it is an expression of **bias favoring the bourgeois narrative**. 

> Additionally, the article treats the current situation (workers being underpaid and feeling compelled to strike) as a background detail, not the core issue. This suggests an **ideological bias**: the systemic issue of exploitation – workers potentially not receiving fair wages or conditions – is not examined. Instead, the focus is on the “disruption” caused by the strike. This aligns with a capitalist ideological framework where keeping production running smoothly is a priority, and any challenge to that (even if due to unfair conditions) is seen negatively. A Marxist analysis would point out that this is a form of **epistemic bias** – the article is written from the standpoint that maintaining the existing economic order is inherently good, thus it frames those who challenge it (the strikers) in a subtly negative light. 

> In conclusion, the bias in this article goes beyond just who gets to speak; it’s embedded in the very framing of what the problem is. By focusing on stability and losses (a bourgeois concern) and neglecting the justice of the workers’ demands (a proletarian concern), the article serves the ideological function of upholding the status quo. A reader only exposed to this narrative might unconsciously adopt the view that the strike is troublesome and that the authorities and factory owners are protectors of social stability. This exemplifies how media content can reflect and reinforce class biases: here, siding with capital over labor. From the Marxist viewpoint, a more balanced article would have treated the workers’ concerns as equally valid and examined the strike as a symptom of deeper issues in the capitalist system, rather than merely a disruption to be managed.

Notice how different this answer is in both **tone and content**. Thanks to the epistemology frame, the LLM has produced an analysis that reads as if a human Marxist scholar might have written it. It explicitly calls out class interests (“bourgeoisie vs proletariat”), uses Marxist concepts (ideological hegemony, capitalist standpoint, exploitation), and identifies biases that go deeper than surface level. It didn’t just say “one side is emphasized more”; it explained *why* that matters, tying it to the maintenance of power structures and the normalization of certain values. This is the kind of depth Priya was looking for.

To directly compare the two outputs (without frame vs. with frame), we can see the transformation:

| **Without Epistemology Frame** (Generic Analysis)                                                                 | **With Marxist Epistemology Frame** (Marxist Analysis)                                                      |
|-------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| *Highlights that the article favors management’s perspective and notes workers’ voices are limited, suggesting bias toward the official viewpoint.* <br> *Mentions economic stability focus, implying the article leans anti-strike, but offers no ideological context beyond “bias”.* | *Emphasizes that the article’s bias serves the interests of the ruling class (bourgeoisie) over workers (proletariat).* <br> *Discusses how framing the strike as a threat to order is an ideological choice that normalizes capitalist priorities, directly using concepts from Marxist theory (class struggle, hegemony, exploitation) to explain the bias.* |

In the side-by-side comparison above, the **left column** (without frame) is a neutral analysis identifying an imbalance, while the **right column** (with Marxist frame) is an ideologically charged analysis explaining the class bias and its implications. The latter is clearly more aligned with what Priya needed for her specific audience and purpose.

This example demonstrates how applying the Epistemology Frame pattern can drastically reshape the output. A few key observations from this exercise:

- **The relevance of details in the frame:** Notice that Priya didn’t just say “analyze from a Marxist perspective” and leave it at that. She provided specific guidance (class interests, type of language to look for, etc.). This made the LLM’s job easier. The model isn’t truly *reasoning* like a human Marxist from first principles – it’s following the cues given. The better the cues, the more authentic the output. Our example frame drew on an existing Marxist framework document, which acted like an outline for the LLM to follow. If Priya had given fewer details, the output might have been less comprehensive. This shows the value of including key tenets of the worldview in the prompt.

- **Tone management:** The output with the Marxist frame was passionate about the class analysis, but it remained an analysis, not a rant. This was influenced by Priya’s instruction to stay explanatory and evidence-based. It’s an important part of using an epistemology frame effectively: you often want the model to adopt the perspective’s insights and values without devolving into one-sided ranting. In practice, if the first attempt came out too strident, Priya could adjust the frame by adding a line like “Avoid overly emotional language; present this analysis as a report grounded in facts, albeit from a Marxist viewpoint.” In our case, the balance was pretty good – the model made strong points but backed them up by referring to what was in the article.

- **Effort vs. payoff:** Crafting the frame took some effort. Priya had to summarize the Marxist approach and effectively prepend it to her question. This made the prompt longer and took more of her time than the first try. However, the payoff was a response that likely saved her a lot of editing time. Without the frame, she might have had to manually inject the class analysis herself into the neutral answer, which could be just as time-consuming (and requires her own expertise). This is a general trade-off with the Epistemology Frame: you invest more in the prompt to get a more tailored result, shifting the workload to the front (prompt writing) rather than the back (editing the answer).

While our scenario focused on a Marxist perspective and media bias, the Epistemology Frame pattern is versatile. You can apply it to countless other situations where a specific worldview or methodology is needed:

- **Educational content:** Suppose an education officer is using an LLM to generate curriculum materials. They might use an epistemology frame for, say, an indigenous perspective on history, ensuring the content isn’t just the standard textbook narrative but integrates the worldview and values of a particular culture. By providing the model with key principles of that culture’s epistemology (for example, emphasizing community, oral traditions, relationship with the land, etc.), the output will reflect those principles in lesson plans or explanations.

- **Policy drafting:** A policy writer in a government might need to draft documents from a particular ideological stance (perhaps a socialist welfare-oriented stance, or conversely a free-market economic stance). If they prompt an LLM without a frame, they might get a generic policy draft that doesn’t strongly align with their government’s philosophy. By framing the prompt (“Draft this policy outline using the principles of Islamic finance and social justice…” or “…using libertarian principles of minimal state intervention…”), they guide the LLM to include arguments and justifications consistent with that ideology.

- **Creative writing and role-play:** Even outside formal contexts, an epistemology frame can help in creative tasks. A user could ask an LLM to explain a concept *as a Stoic philosopher would*, or to have a debate where one side uses a utilitarian ethic and the other a deontological ethic. The key is telling the model the rulebook it should follow for its reasoning. This can make the difference between a shallow impersonation and a convincing rendition of that viewpoint.

In applying this pattern, it’s often useful to remember that **you are, in effect, “lending” the model a mindset**. If you have a well-defined set of principles or questions that someone from a certain school of thought would use, feed those to the model. In our example, the Marxist framework acted like a checklist (Who benefits? Whose voice is heard? What assumptions are made about normalcy?). Framing your prompt with such questions or principles gives the model a clear map.

One practical tip is to keep your epistemology frame text separate, especially if you’ll reuse it. As noted, some practitioners maintain separate prompt files for their favorite frames (be it Marxist, scientific skeptic, religious conservative, etc.). They can prepend or attach these when needed, rather than writing from scratch each time. In a workflow, you could have a “Perspective Library.” For Priya, if she often needs Marxist analyses, she now has a Marxist frame ready to go for any future article. She could similarly have a “Feminist analysis frame” or a “Libertarian policy frame” saved elsewhere. When needed, she pastes the relevant frame into the prompt and then adds her specific question/task. This modular approach makes using Epistemology Frames more efficient.

Before concluding, it’s worth noting that using an Epistemology Frame is a powerful technique, but it doesn’t mean the LLM will always get things perfect just from one prompt. You saw how much richer the answer became with the Marxist frame — along with that richness came a stronger bias in the output (intentionally). In some cases, after getting the framed output, a user might want to dial it back a bit or cross-check facts. For instance, Priya might double-check that the original article indeed had no worker quotes (to ensure the AI isn’t hallucinating bias that’s not there – though in our prompt we gave it the info, so it’s fine). Generally, though, if the frame is accurately written, the model will stay on track. The main point is that the frame gives the model a direction to run toward; without it, the model was wandering aimlessly in the field of “could be this, could be that.” With the frame, it sprinted down a specific path.

In conclusion, the **Epistemology Frame** pattern allows you to fundamentally shape the worldview from which the LLM generates an answer. For users like civil servants, educators, or analysts who operate in contexts where *how* you say something is as important as *what* you say, this is invaluable. It helps ensure the AI’s output isn’t just generally competent, but specifically aligned with the perspective that matters for the task. By understanding the challenges of default LLM behavior (neutrality and hidden bias) and applying a well-crafted ideological or methodological lens, users can transform generic AI responses into insightful, angle-perfect ones. The example of Priya’s Marxist analysis of a news article illustrates the dramatic improvement in relevance and depth that an epistemology frame can provide. It’s like switching the AI’s glasses: with the right lenses on, it will see the problem in the shades and colors you need, and describe it in those terms.