### Exhaustive Input  
Provide as much information as possible; more context yields better results.

**Challenge:** If a prompt only includes minimal information, the LLM might not have enough context to generate a good answer. Important details or background could be missing, forcing the model to fill gaps with assumptions or general knowledge. This often leads to inaccuracies or overly generic responses, especially on specialized topics where every detail matters.

**Solution:** Give the LLM as much relevant information as you can when writing your prompt. Include all necessary background, data, and specifics so that little is left to assumption. The larger the knowledge base you provide, the better the LLM can understand and perform the task. In practice, this might mean providing lengthy descriptions, data excerpts, or multiple pieces of context â€” essentially, err on the side of too much information rather than too little (as long as it's relevant).