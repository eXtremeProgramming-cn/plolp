# Problem Orientation
*Start with the big picture to clarify the prompt's goal.*

## Motivation
If you ask a large language model to perform a task without first explaining the overall problem, you risk getting unfocused or off-target results. When a prompt dives straight into details without context, the model might not understand what the real objective is or which aspects are most important. The response can then wander off topic or fail to address the core issue.

## Solution
Begin your prompt by describing the challenge in broad terms and outlining the desired outcome. Provide the high-level context and goals **before** getting into specifics. By establishing this "big picture" first, you give the model a clear target to aim for, helping it align its answer with your overall objective. In other words, set the stage at the very start of your prompt so the AI knows exactly what you are trying to accomplish. Even a brief, one- or two-sentence introduction can orient the model effectively.

## Challenge
Many people make the mistake of diving straight into a request when writing a prompt, without ever mentioning the larger problem they are trying to solve. Think about asking a question in a vacuum: if you provide no background or goal, the answer you get may miss the mark. This pattern addresses a common issue where prompts lack a clear **problem orientation** – that is, they don't start by telling the AI what the overarching issue or objective is.

Without a clear problem orientation at the beginning of your prompt, a large language model is left to guess what you're really after. It might latch onto a minor detail you mentioned and focus on that, or it could generate a very generic response because it isn’t sure what specific angle you care about. In either case, the result is often an answer that feels only loosely related to what you actually needed. The core reason is simple: the AI doesn’t **truly know your goal** unless you tell it upfront. Even though these models are incredibly advanced, they don't have mind-reading capabilities or true understanding of your intentions beyond the words you provide.

For example, when a prompt lacks a clear problem orientation, you might notice:  
- **Generic answers:** The response is broad and could apply to almost any situation, indicating the AI wasn’t sure what you specifically needed.  
- **Off-topic details:** The AI latches onto a detail from your prompt that isn’t really the main point, leading it down a tangent.  
- **Missed objectives:** The core question or problem you have goes unaddressed, because the model didn’t realize that was the focus.  
- **Need for clarification:** You find yourself having to ask follow-up questions or re-explain the situation after the first answer, essentially adding the context you should have provided from the start.

To illustrate, imagine you go to an expert for advice but give no context. Suppose you ask, *"What should I do next?"* and nothing more. The expert would likely furrow their brow and respond with generic suggestions like *"Well, you could try to improve yourself, work hard, maybe take up a new hobby..."* Such advice is vague, because the expert has no idea **what situation** you are talking about. Are you asking about your career, your personal life, or something else entirely? Without knowing the problem or context, even a human expert will default to broad, bland answers.

An AI works in much the same way. If you prompt an AI with a question like, *"How can I improve my project?"* and nothing else, it will try to answer in a general way. The response might come back with a laundry list of common improvement tips that could apply to just about any project. For example, it might say, *"Set clear goals, get feedback from others, stay organized, and measure your results."* While such tips are not wrong, they may be painfully obvious or not directly applicable to your specific situation. The AI isn't being lazy or intentionally unhelpful; it simply wasn't given any direction on what **kind** of project you're working on or what kind of improvement you are aiming for.

In contrast, when you start by stating the problem or context, you guide the AI toward the territory you care about. Imagine revising the question to something more specific: *"I manage a community garden project that has too few volunteers and declining crop yields. How can I improve this project?"* Now the AI has a much clearer picture. It knows the domain (community gardening), a key challenge (few volunteers, low yields), and the goal (improve the project). With that context, the AI’s answer will almost certainly be more relevant — perhaps suggesting ways to attract more volunteers or better farming techniques. By providing the big picture first, you prevented the AI from guessing and instead pointed it directly at the heart of your problem. (This principle isn't limited to advice questions—it's equally true for any kind of prompt, whether you're asking the AI to summarize a report, write a story, or explain a concept. Stating your overall aim or problem first will steer the response in the right direction.)

For instance, if you ask the AI to *"summarize a technical report,"* without explaining your purpose, you might get a very dense, jargon-filled summary. But imagine your real goal was to understand it in simple terms. If you had instead started with something like, *"I need a plain-language summary of a technical report for a non-expert audience,"* the AI would know to simplify the language and focus on the broader points.

Now consider creative or communication tasks. Simply telling the AI, *"Write a story about a hero,"* or *"Draft an email to my boss,"* is extremely open-ended. You could get anything from a medieval knight tale to a science fiction adventure for the story, or a very generic message for the boss. The AI has to guess the context: what kind of hero story do you want, or why are you emailing your boss? If what you really wanted was a **children's bedtime story** about a brave kitten who learns to share, you should say so at the outset. And if you need to email your boss about, say, a project delay, start your prompt by explaining that scenario: *"I need to write my boss to explain why a project is delayed and how I'll get it back on track."* By presenting the purpose and context first, you give the AI the guidance it needs to shape the entire response appropriately.

This lack of initial context is a frequent reason why prompts fail to yield useful results. Sometimes, users skip giving context because they assume the AI "should know what they mean" or they want to keep the prompt short. However, unlike a human conversation partner, the AI has no awareness outside of what you explicitly tell it (aside from any earlier dialogue in the same chat). There's really no downside to adding a sentence or two of background. In fact, those extra words can be the difference between an answer that misses the point and one that hits the bullseye. Users might conclude *"the AI just doesn't get it"* or *"ChatGPT is giving me irrelevant answers,"* when in reality the prompt never gave the AI a fair chance to understand what was needed. The model has access to an enormous amount of information, but it operates only on the input it’s given. If the input is narrow or out-of-the-blue, the output will be correspondingly unfocused. Think of it like trying to solve a puzzle without seeing the picture on the box — you might connect a few pieces, but you probably won’t see the whole image properly.

In everyday conversation, we naturally set context for one another. If you want to get good advice from a colleague, you usually start by saying something like, *"I'm dealing with a situation at work where..."* before posing your question. Or if you email a teacher to ask for help, you might begin with, *"I'm working on a history project about World War II and I'm struggling with..."* and then ask your question. We do this because we know that without context, our questions can be interpreted too broadly. The same principle applies to communicating with AI: you need to **frame the question** so the AI knows what context to assume.

From a technical perspective, providing context at the start of a prompt is crucial because of how these models generate responses. A large language model reads your prompt word by word, kind of like how you read a sentence. The beginning of the prompt sets the stage for everything that comes after. If the stage is empty (no big picture given), the model will fill it with its best guess of the scenario, which might not be what you intended. However, if you paint the backdrop first by stating the overall problem, the model uses that backdrop to inform all of its choices as it writes the answer. In simple terms, the AI can only be as focused as you are. If your question is floating without an anchor, the AI's answer will float too.

The author of this book learned the importance of *problem orientation* in a completely different field: academic writing. Whenever he brought a draft to his professor, the first question she would ask was, *"What's your problem orientation here?"* It was her way of saying: *Start by explaining what problem you are trying to solve or question you are trying to answer.* If that part was missing or unclear, the rest of the paper would inevitably wander or lack cohesion. That lesson applies just as much to prompt writing. If you don’t articulate the core problem at the outset of a prompt, the AI’s response is likely to wander or miss the point, just like an unfocused essay.

Interestingly, formulating that high-level problem statement isn’t just for the AI’s benefit – it also helps **you**. When you take a moment to summarize the core issue in your prompt, you might clarify your own thoughts and intentions. Many people have found that by writing out a sentence about what they are trying to accomplish, they themselves get a better grasp of their request. This leads to a more focused question and, in turn, a more useful answer. In the professor's example, being forced to articulate the problem orientation improved the student's writing; in the same way, doing so in a prompt can improve the question you're asking.

In summary, the challenge this pattern addresses is that prompts without a clear problem orientation often produce subpar results. They fail not because the AI is incapable, but because it was never properly aimed at the target. To get effective results, you need to **point the AI in the right direction** from the very first sentence of your prompt. Neglecting to do so is like sending someone on a journey without telling them the destination – they'll travel somewhere, but it may not be where you wanted to go. For this reason, one of the first things to check when an AI's response misses the mark is your prompt itself. Ask yourself: *Did I clearly explain what I'm trying to accomplish?* If not, try rewriting the prompt to lead with that context. Often, you'll find the AI's next answer hits much closer to the target once it knows the big picture.

## Example
Let's walk through a concrete scenario to see how **Problem Orientation** can make a difference. Imagine you own a small business – say a local organic bakery. You want to use an AI assistant to get ideas on how to improve your bakery and attract more customers. It's a busy day, so you quickly type out a prompt to ask for advice, without giving much background. Your initial prompt might look like this:

> **Initial Prompt (without context):** How can I improve my business?  
>  
> **AI's Response:** You can improve your business by focusing on providing great customer service, investing in marketing to increase your visibility, ensuring you offer quality products or services, and responding to customer feedback. Consider expanding your online presence through social media and possibly offering promotions or discounts to attract new customers. By understanding your customers' needs and continuously refining your business strategy, you can gradually see improvement in your business performance.

At first glance, this answer might seem okay. The AI did provide some advice on improving a business. But if you think about it, the response is extremely generic. It reads like a list of common-sense business tips that could apply to **any** business, whether it's a bakery, a tech startup, or a landscaping service. The advice isn't wrong, but it's not particularly insightful or tailored to your situation. It doesn't mention anything specific about bakeries or local businesses, because your prompt never mentioned those details either. As the bakery owner, you probably already knew you should "focus on customer service" and "use marketing" – you're looking for fresh ideas, not a reheated list of basics. It's a bit disappointing, because it doesn't feel tailored to your bakery at all.

Now, let's analyze why the answer was so generic. When you provided the prompt, you didn't give the AI any information about what kind of business you run, what challenges you're facing, or what specific goal you have in mind. The AI only saw the words *"improve my business"* and had to guess the rest. With no further context, the safest thing for the model was to offer broad advice that would be true for most businesses. In other words, the AI wasn't aiming at a clear target – it was shooting in the dark and covering the basics, hoping something would be relevant.

Let's apply the **Problem Orientation** pattern to this situation. The idea is to start the prompt with the big picture: give the AI some context about your business and what you are trying to achieve. Instead of just asking the question cold, we will lead with a brief introduction. For example, we might write a new prompt like this, which includes a sentence or two of context before the question:

> **Revised Prompt (with Problem Orientation):** I run a small organic bakery in a town dominated by big chain supermarkets and franchise coffee shops. My bakery has loyal local customers but we struggle to compete with the marketing and convenience of the big chains. I want to attract more local customers and stand out as a unique option in our community. What are some strategies I can use to improve my bakery's business, especially in terms of marketing and product offerings?  
>  
> **AI's Response:** Since you run a small organic bakery facing competition from larger chains, you should emphasize what makes you unique. For example, highlight the organic, artisanal quality of your baked goods – this is something the big supermarkets can't offer. You could host tasting events or workshops (like "bread baking 101" for the community) to draw people in and create buzz. In terms of marketing, focus on local social media groups and perhaps partner with other local businesses (like coffee shops or farmers' markets) to cross-promote each other. You might also introduce a customer loyalty program or a special "local flavor of the week" to keep people coming back. By leveraging your bakery's homegrown appeal and engaging with the community, you can draw customers who prefer a personal touch over the big chains.

Notice how much more specific and actionable this second answer is. The AI is no longer giving one-size-fits-all advice; instead, it's addressing the **particular situation** of an organic bakery competing against big chains. It mentions things like highlighting organic quality, doing local workshops, and partnering with other local businesses – none of which appeared in the first answer. This is because our revised prompt painted a clear picture of the problem upfront, and the AI followed that guidance. In fact, the first answer didn't even mention the word *"bakery"* once – how could it, since it didn't know what kind of business you had. The revised answer, on the other hand, explicitly talks about baked goods and local bakeries, showing that the AI is now zeroed in on your context.

Why was the second answer so much better? The AI didn't suddenly get smarter between the first and second attempt – we simply gave it better directions. Without context, the model was probably drawing on general "how to improve a business" advice it learned from countless sources. But once we mentioned a bakery and local competition, the AI could tap into more relevant knowledge (like strategies for small food businesses and community marketing) because those keywords steered it toward a different, more specific subset of its training data. In effect, we told it exactly which playbook to pull ideas from. The first time, it had to grab the broad business advice playbook; the second time, it grabbed the small bakery playbook.

Let's break down what changed between the two prompts and why the second prompt worked better:  
- **Context added:** The revised prompt starts by stating that you run a small organic bakery and that your town has big chain competitors. These two sentences set the stage, informing the AI about the industry (bakery), scale (small, local), and competitive landscape (big chains).  
- **Specific challenge identified:** We included the detail that you're struggling to compete with the marketing and convenience of larger chains. This tells the AI exactly what problem you're looking to overcome (losing customers to bigger competitors).  
- **Clear goal stated:** The prompt explicitly says you want to attract more local customers and stand out as a unique option. Now the AI knows the objective: to help the bakery differentiate itself and draw in locals.  
- **Focus on certain areas:** The question at the end of the prompt specifies "especially in terms of marketing and product offerings." This directs the AI to concentrate on those aspects when suggesting strategies, rather than, say, advising on financing or other areas you might not be interested in right now.

By making these changes, we gave the AI a much better understanding of the problem. The model didn't have to guess what kind of business we were talking about or what *“improve”* meant in this context — we told it upfront. As a result, the AI could zero in on relevant suggestions that make sense for a bakery in that specific scenario. In essence, we pointed the AI's flashlight at the target we cared about, rather than leaving it in a dark room to find its own way.

Importantly, adding this problem-oriented context at the beginning of your prompt doesn't make the prompt too long or complicated. In our example, it only took a couple of sentences to explain the situation. Those few extra moments you spend describing the big picture can save you time later, because you're more likely to get a useful answer on the first try instead of having to ask follow-up questions or clarify what you meant.

The above example is fictional, but it reflects a pattern that many users encounter in real life. In fact, experienced prompt designers often **start with a bit of background** just like we did, especially for complicated tasks. They know that an upfront investment in context pays off in a more accurate response. For example, if the task is to summarize an article for a particular audience, a well-crafted prompt might begin with something like, *"This summary is for a high school science class, so explain the concepts in simple terms..."* before providing the article text. If the task is to write a short story, the prompt might open with a line about the desired theme or audience, such as *"Write a children's bedtime story about..."*. These openings serve the same purpose: telling the AI what the big picture is, so it can shape its output accordingly.

So whenever an AI's response seems off-target or disappointingly generic, try revisiting your prompt. Often, the fix is as simple as adding a sentence at the very start that clearly states the problem you're trying to solve or the context of your request. You'll be surprised how much of a difference it makes. Whether you're asking for business advice, seeking writing help, generating creative ideas, or anything else, leading with the big picture ensures the AI is working **with** you on the right problem from the get-go.

As a quick guideline, when crafting your own prompts, try to answer these in the very first lines: *Who or what is involved? What is the main challenge or context? What outcome are you looking for?* For our bakery example, it was: *small bakery (who/what), struggling against big chains (challenge), wants to attract locals (outcome).* Framing your prompt in this way ensures the AI understands the scenario and goal right from the start.
